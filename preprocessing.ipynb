{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:50.616528Z",
     "start_time": "2025-12-17T12:14:46.438684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pandas.core.interchange.from_dataframe import primitive_column_to_ndarray"
   ],
   "id": "1840f386a732fdf8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:15:07.722865Z",
     "start_time": "2025-12-17T12:15:07.576845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load the dataset from HF\n",
    "df_full = pd.read_parquet(\"hf://datasets/ruggsea/stanford-encyclopedia-of-philosophy_chat_multi_turn/data/train-00000-of-00001.parquet\")"
   ],
   "id": "ce3a685ebceef307",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# load the dataset from HF\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df_full \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_parquet(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhf://datasets/ruggsea/stanford-encyclopedia-of-philosophy_chat_multi_turn/data/train-00000-of-00001.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:651\u001B[0m, in \u001B[0;36mread_parquet\u001B[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001B[0m\n\u001B[0;32m    498\u001B[0m \u001B[38;5;129m@doc\u001B[39m(storage_options\u001B[38;5;241m=\u001B[39m_shared_docs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    499\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mread_parquet\u001B[39m(\n\u001B[0;32m    500\u001B[0m     path: FilePath \u001B[38;5;241m|\u001B[39m ReadBuffer[\u001B[38;5;28mbytes\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    508\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    509\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[0;32m    510\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;124;03m    Load a parquet object from the file path, returning a DataFrame.\u001B[39;00m\n\u001B[0;32m    512\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    648\u001B[0m \u001B[38;5;124;03m    1    4    9\u001B[39;00m\n\u001B[0;32m    649\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 651\u001B[0m     impl \u001B[38;5;241m=\u001B[39m get_engine(engine)\n\u001B[0;32m    653\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_nullable_dtypes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n\u001B[0;32m    654\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    655\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe argument \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muse_nullable_dtypes\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is deprecated and will be removed \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    656\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min a future version.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    657\u001B[0m         )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:67\u001B[0m, in \u001B[0;36mget_engine\u001B[1;34m(engine)\u001B[0m\n\u001B[0;32m     64\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m     65\u001B[0m             error_msgs \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m - \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(err)\n\u001B[1;32m---> 67\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m     68\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to find a usable engine; \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     69\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtried using: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpyarrow\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfastparquet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     70\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA suitable version of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     71\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyarrow or fastparquet is required for parquet \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     72\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msupport.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     73\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrying to import the above resulted in these errors:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     74\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_msgs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     75\u001B[0m     )\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m engine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyarrow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m PyArrowImpl()\n",
      "\u001B[1;31mImportError\u001B[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:34:28.911099Z",
     "start_time": "2025-12-12T21:34:28.902479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I recommend to work on mock dataset (50 first rows) for writing the code\n",
    "df = df_full.head(5)\n",
    "df.head()"
   ],
   "id": "177515ff32dbecb7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                        conversation  \\\n",
       "0  [{'content': 'Professor, I was thinking about ...   \n",
       "1  [{'content': 'Professor Phil, do we always cho...   \n",
       "2  [{'content': 'Professor Phil, I was reading th...   \n",
       "3  [{'content': 'Professor Phil, I've been wonder...   \n",
       "4  [{'content': 'Professor, I've been thinking ab...   \n",
       "\n",
       "                                              prompt  \n",
       "0  You are an expert and well-read Philosophy pro...  \n",
       "1  You are an expert and well-read Philosophy pro...  \n",
       "2  You are an expert and well-read Philosophy pro...  \n",
       "3  You are an expert and well-read Philosophy pro...  \n",
       "4  You are an expert and well-read Philosophy pro...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'Professor, I was thinking about ...</td>\n",
       "      <td>You are an expert and well-read Philosophy pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'content': 'Professor Phil, do we always cho...</td>\n",
       "      <td>You are an expert and well-read Philosophy pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'content': 'Professor Phil, I was reading th...</td>\n",
       "      <td>You are an expert and well-read Philosophy pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'content': 'Professor Phil, I've been wonder...</td>\n",
       "      <td>You are an expert and well-read Philosophy pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'content': 'Professor, I've been thinking ab...</td>\n",
       "      <td>You are an expert and well-read Philosophy pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:34:32.456231Z",
     "start_time": "2025-12-12T21:34:32.453314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_content(conversation: dict):\n",
    "    \"\"\"\n",
    "    Unwraps original dictionary with student's and professor utterances.\n",
    "    :param conversation: dict with utterances\n",
    "    :return: list of professor utterances and student utterances\n",
    "    \"\"\"\n",
    "    professor = []\n",
    "    user = []\n",
    "    for turn in conversation:\n",
    "        # print(turn)\n",
    "        # print('-'*20)\n",
    "        if turn['role'] == 'user':\n",
    "            user.append(turn['content'])\n",
    "        else:\n",
    "            professor.append(turn['content'])\n",
    "    return professor, user\n",
    "\n",
    "def prepare_prompt(prompt: str):\n",
    "    \"\"\"\n",
    "    Cleans the redundant content from each prompt. Desgined to use with lambda.\n",
    "    :param prompt: prompt to clean\n",
    "    :return: cleaned prompt\n",
    "    \"\"\"\n",
    "    return re.findall(r'\\\"([\\s\\S]+?)\\\"', prompt)\n"
   ],
   "id": "63c1e3a3f8e8a4d0",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:34:34.006389Z",
     "start_time": "2025-12-12T21:34:34.002430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the conversation into various rows in df\n",
    "# select utterances of professor\n",
    "df['professor'] = df['conversation'].apply(lambda x: extract_content(x)[0])\n",
    "\n",
    "# select utterances of student\n",
    "df['student'] = df['conversation'].apply(lambda x: extract_content(x)[1])\n",
    "\n",
    "# clean redundant content from prompt\n",
    "df['prompt'] = df['prompt'].apply(lambda x: prepare_prompt(x))"
   ],
   "id": "32e3fb9a0753ec8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quiz0\\AppData\\Local\\Temp\\ipykernel_27332\\959540336.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['professor'] = df['conversation'].apply(lambda x: extract_content(x)[0])\n",
      "C:\\Users\\quiz0\\AppData\\Local\\Temp\\ipykernel_27332\\959540336.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['student'] = df['conversation'].apply(lambda x: extract_content(x)[1])\n",
      "C:\\Users\\quiz0\\AppData\\Local\\Temp\\ipykernel_27332\\959540336.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prompt'] = df['prompt'].apply(lambda x: prepare_prompt(x))\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:34:35.708928Z",
     "start_time": "2025-12-12T21:34:35.706020Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.drop('conversation', axis=1)",
   "id": "781044d933a69cee",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:41:25.952336Z",
     "start_time": "2025-12-12T21:41:25.946639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.explode([\"professor\", \"student\"]) # powerful line! creates a pair of student-professor utterance for each row\n",
    "df.info()"
   ],
   "id": "d783beacda4c6d74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   prompt     21 non-null     object\n",
      " 1   professor  21 non-null     object\n",
      " 2   student    21 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 672.0+ bytes\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T21:44:08.227098Z",
     "start_time": "2025-12-12T21:44:08.218072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now data is clean!\n",
    "df.head()\n",
    "df.to_csv('dfs/preprocessed-df.csv', index=False) # save it for future work"
   ],
   "id": "cd7b5ada62c9026",
   "outputs": [],
   "execution_count": 112
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
